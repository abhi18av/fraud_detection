---
title: "scratch"
output: html_document
---


```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir = normalizePath("/Users/eklavya/projects/education/formalEducation/DataScience/DataScienceAssignments/FinalProject/fraud_detection/"))  
```



```{python}

import os
os.chdir("/Users/eklavya/projects/education/formalEducation/DataScience/DataScienceAssignments/FinalProject/fraud_detection/")


```


# Credit Card Fraud Detection

```{python}

import numpy as np 
import pandas as pd 
import scipy as sp
#import tensorflow as tf
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA, TruncatedSVD
import matplotlib.patches as mpatches
import time

# Classifier Libraries
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
import collections


# Other Libraries
from sklearn.model_selection import train_test_split
from sklearn.pipeline import make_pipeline
#from imblearn.pipeline import make_pipeline as imbalanced_make_pipeline
#from imblearn.over_sampling import SMOTE
#from imblearn.under_sampling import NearMiss
#from imblearn.metrics import classification_report_imbalanced
from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report
from collections import Counter
from sklearn.model_selection import KFold, StratifiedKFold

import warnings
warnings.filterwarnings('ignore')
sns.set_style('whitegrid')
sns.set_context('paper')


# Pandas options
pd.set_option('display.max_colwidth', 1000, 'display.max_rows', None, 'display.max_columns', None)

# Plotting options
#%matplotlib inline
plt.style.use('ggplot')
sns.set(style='whitegrid')



def print_ln():
    print('-' * 80, '\n')


```



# Splitting the data into train & test data

```{python}

df = pd.read_csv('./data/raw/creditcard.csv')
df.head()

```


```{python}

X = df.drop(labels='Class', axis=1) # Features
y = df.loc[:,'Class']               # Response


```



```{python}
from sklearn import model_selection

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1, stratify=y)

# Preserve X_test & y_test to evaluate on the test data once you build the model

print(np.sum(y))
print(np.sum(y_train))
print(np.sum(y_test))


```



# Plotting the distribution of a variable



That's a strong right skew. Let's use a power transform to bring the transaction amounts closer to a normal distribution. We'll use the Box-Cox transform in SciPy, but some of the amounts are zero (min = 0 above), so we need to shift the amounts first to make them positive. We'll shift by a very small amount, just $10^{-9}$.


```{python}
X_train.loc[:,'Amount'] = X_train['Amount'] + 1e-9 # Shift all amounts by 1e-9

# Perform the Box-Cox transform:

X_train.loc[:,'Amount'], maxlog, (min_ci, max_ci) = sp.stats.boxcox(X_train['Amount'], alpha=0.01)
```



```{python}

# plot the histogram of a variable from the dataset to see the skewness

```



```{python}


# ### If there is skewness present in the distribution use:
# - <b>Power Transformer</b> package present in the <b>preprocessing library provided by sklearn</b> to make distribution more gaussian

# In[ ]:


# - Apply : preprocessing.PowerTransformer(copy=False) to fit & transform the train & test data


# In[ ]:


# plot the histogram of a variable from the dataset again to see the result 

```


